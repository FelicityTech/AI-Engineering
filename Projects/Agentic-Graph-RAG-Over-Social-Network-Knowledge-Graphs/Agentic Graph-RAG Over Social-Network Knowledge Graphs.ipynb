{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Agentic Graph-RAG Over Social-Network Knowledge Graphs**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Understanding **influence** and **information flow** in social networks requires more than retrieving text snippets or isolated documents. Traditional **Retrieval-Augmented Generation (RAG)** pipelines rely on **vector search** over unstructured text, which works well for semantic similarity but ignores **relational structure**, **community topology**, and the **multi-hop pathways** through which influence spreads. To analyze a social graph meaningfully, an AI system may incorporate **graph structure** directly into the retrieval process.\n",
    "\n",
    "This lab introduces an extended **Graph-RAG** approach: instead of retrieving documents, the agent retrieves **subgraphs**, neighborhoods of users connected by follow relationships, and treats these graph fragments as the context for downstream reasoning. This shift from document-level retrieval to **graph-aware retrieval** enables the system to capture richer signals such as **connectivity**, **centrality**, and **cross-community interactions**.\n",
    "\n",
    "The dataset used in this lab is a curated **Facebook Page–Page network** originally derived from the public **MUSAE Facebook dataset**, with additional attributes prepared for **graph-based retrieval** and **influence modeling**. You will work with a real-world dataset containing **over twenty-two thousand users** and **more than three hundred thousand directed edges**, forming a dense and highly interconnected social-network graph. After constructing this graph, you will engineer a variety of **structural features**, including **PageRank**, **degree patterns**, **k-core values**, **clustering coefficients**, and **topic similarity scores**, to describe each node’s position and relevance within the network. These features are then used to train a **Graph Convolutional Network (GCN)** that learns to estimate **influence** based on both **local** and **global** graph structure. The GCN becomes a learned **ranking module** that can distinguish **high-impact users** from **peripheral users**, producing numerical **influence scores** grounded in measurable graph evidence.\n",
    "\n",
    "Once the graph representation and GCN ranker are in place, you will integrate them into an agent built with **LangGraph**. The agent **plans** its steps, **retrieves** a meaningful subgraph in response to a natural-language query, **scores** the nodes inside that subgraph using the GCN, and **synthesizes** the results through an **LLM**. This creates a full **Agentic Graph-RAG pipeline** where **retrieval is structural**, **ranking is learned**, and **reasoning is generative**.\n",
    "\n",
    "By the end of the lab, you will have a functioning system capable of identifying **influential nodes**, explaining **why they matter**, and generating concise, actionable **outreach recommendations**, demonstrating how **graph intelligence**, **neural modeling**, and **LLM reasoning** work together to produce deeper, more context-aware insights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    "- Construct a social-network knowledge graph from CSV data and manage node attributes, directed edges, and graph connectivity using pandas and NetworkX.\n",
    "- Engineer graph-based features such as PageRank, in/out degree, k-core values, clustering coefficients, and topic similarity, preparing them for use in a neural network model.\n",
    "- Train and evaluate a Graph Convolutional Network (GCN) that learns to estimate influencer importance based on structural and semantic information across the graph.\n",
    "- Implement a Graph-RAG retrieval module that extracts relevant neighborhoods in response to a natural-language query and integrates them into an agentic workflow.\n",
    "- Build a multi-step LangGraph agent that plans, retrieves, scores with the GCN, and synthesizes an LLM-generated summary with actionable insights grounded in graph evidence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The agent in this lab follows a **multi-step, graph-aware reasoning pipeline** that integrates **LangGraph for planning**, **GCN-based ranking for influence estimation**, and **LLM-based synthesis for explanation and decision support**.\n",
    "\n",
    "The diagram below summarizes the end-to-end system: **Agentic Graph-RAG (LangGraph + GCN + LLM)**.\n",
    "\n",
    "<p style=\"text-align:center;\">\n",
    "  <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/9-UIxRFsxZf6XdUzF8ItfQ/Graph-RAG.png\"\n",
    "       alt=\"Agentic Graph-RAG Pipeline\"\n",
    "       width=\"90%\">\n",
    "  <br>\n",
    "  <em>Figure. Overview of the Agentic Graph-RAG Pipeline.</em>\n",
    "</p>\n",
    "\n",
    "Rather than retrieving isolated documents, the agent retrieves and reasons over **subgraphs**, allowing structural signals such as connectivity, neighborhood influence, and multi-hop relationships to directly inform the final response.\n",
    "\n",
    "Each stage of the pipeline contributes a distinct capability:\n",
    "\n",
    "- **User Query → PLAN**  \n",
    "  LangGraph interprets the natural-language query and infers relevant high-level topics and intent.\n",
    "\n",
    "- **PLAN → RETRIEVE**  \n",
    "  A relevant subgraph is extracted from the Facebook Page–Page network by seeding topic-matched nodes and expanding through k-hop neighborhoods.\n",
    "\n",
    "- **RETRIEVE → SCORE**  \n",
    "  A trained **Graph Convolutional Network (GCN)** performs message passing over the retrieved subgraph, combining node features and neighborhood structure to produce a **relative influence score** for each node.\n",
    "\n",
    "- **SCORE → SYNTHESIZE**  \n",
    "  The LLM generates a structured summary that explains rankings and recommendations using evidence grounded in the graph.\n",
    "\n",
    "- **SYNTHESIZE → Final Output**  \n",
    "  The agent produces an actionable, human-readable response that combines graph intelligence with language-based reasoning.\n",
    "\n",
    "This workflow highlights how **planning, graph retrieval, learned ranking, and generative synthesis** are composed into a single agentic system, forming the foundation for all experiments implemented in this lab.\n",
    "\n",
    "## GCN-Based Influence Ranking and Modeling\n",
    "\n",
    "To determine which nodes are most important within a retrieved subgraph, this lab uses a **Graph Convolutional Network (GCN)** as a learned influence-ranking model.\n",
    "\n",
    "A GCN is a neural network designed to operate directly on graph-structured data. Instead of processing nodes independently, it applies **message passing** along graph edges, allowing each node to aggregate information from its neighbors. Through stacked convolution layers, nodes progressively incorporate **multi-hop structural context**, capturing relational patterns that cannot be expressed by simple heuristics such as degree or PageRank alone.\n",
    "\n",
    "In this lab, each node is initialized with a feature vector that encodes:\n",
    "- Structural properties (e.g., in-degree, out-degree, PageRank, k-core value, clustering coefficient),\n",
    "- Activity signals (e.g., recent posting behavior),\n",
    "- Query-dependent topic relevance.\n",
    "\n",
    "The GCN propagates and refines node features through the graph structure, learning latent representations that capture both local and multi-hop context. During training, this propagation occurs over the full social-network graph, while at inference time it is applied to retrieved subgraphs. A final linear layer maps each node’s learned representation to a **scalar influence score**. Importantly, the GCN is used as a **ranking model rather than a classifier**. It learns to order nodes by relative influence within a subgraph, which aligns naturally with downstream tasks such as influencer identification and prioritization.\n",
    "\n",
    "Within the Agentic Graph-RAG pipeline, the GCN serves as the bridge between retrieval and generation:\n",
    "- Graph retrieval determines which portion of the network is relevant,\n",
    "- The GCN determines who is most influential within that subgraph,\n",
    "- The LLM explains why those nodes matter, grounding its reasoning in graph-based evidence.\n",
    "\n",
    "This design enables influence estimation that is **learned, context-sensitive, and structurally informed**, providing a stronger foundation for agentic reasoning than purely rule-based or text-only approaches.\n",
    "\n",
    "## From Influence Scores to Agentic Reasoning\n",
    "\n",
    "While the GCN produces numerical influence scores, these scores alone are not the final objective. Their primary role is to **ground agentic reasoning in graph evidence**.\n",
    "\n",
    "Within the Agentic Graph-RAG pipeline, influence scores act as an intermediate signal that guides decision-making rather than a standalone output. They determine which nodes should receive attention, prioritization, and explanation in response to a user query.\n",
    "\n",
    "The agent uses these scores to:\n",
    "- Focus reasoning on the most structurally and contextually important nodes,\n",
    "- Filter noisy or peripheral parts of the graph,\n",
    "- Provide the LLM with ranked, evidence-backed inputs.\n",
    "\n",
    "The LLM then synthesizes this information into human-readable explanations, connecting influence scores to observable graph properties such as connectivity, activity, and topical relevance. This separation of responsibilities **learning influence with a GCN and explaining influence with an LLM** ensures that the final output is both **data-driven and interpretable**.\n",
    "\n",
    "By combining learned influence modeling with agentic planning and language-based synthesis, the system moves beyond static graph analytics and enables **context-aware, query-driven reasoning over large social-network graphs**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "### Installing Libraries\n",
    "\n",
    "The first step is to install all required Python libraries for this lab. This includes LangGraph for agent construction, PyTorch and PyTorch Geometric for the GCN, NetworkX for graph processing, and several utility packages.  \n",
    "\n",
    "Run the cell below to install all dependencies. If the notebook prompts you to restart the kernel afterward, go ahead and do so to ensure all packages load correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "✅ Dependencies installed (you may restart the kernel if needed).\n"
     ]
    }
   ],
   "source": [
    "%pip -q install langgraph pydantic pandas networkx matplotlib tqdm scipy openai\n",
    "%pip -q install torch==2.8.0+cpu torchvision==0.23.0+cpu torchaudio==2.8.0+cpu --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip -q install torch_geometric==2.6.1\n",
    "\n",
    "print(\"✅ Dependencies installed (you may restart the kernel if needed).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Reproducibility\n",
    "\n",
    "Now that all dependencies are installed, we import the libraries used throughout the workflow. We also configure reproducibility by setting global random seeds for Python, NumPy, and PyTorch.  \n",
    "\n",
    "This ensures that the executions are deterministic and repeatable across runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports complete | Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os, json, random\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, Dict, Any, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch_geometric.utils import from_networkx as pyg_from_nx, add_self_loops\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from openai import OpenAI\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "device = torch.device(\"cpu\")  # keep CPU for reproducibility\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "\n",
    "print(\"✅ Imports complete | Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Explore the Social-Network Data\n",
    "\n",
    "In this lab, we work with a curated Facebook Page–Page social graph. The dataset is derived from the public **MUSAE Facebook network**, where each node represents a Facebook page and edges represent page–page relationships. The raw MUSAE files were preprocessed into two simplified CSVs used throughout this lab. These curated files make it easier to build the Graph-RAG pipeline without running the original preprocessing steps yourself.\n",
    "\n",
    "We will use two CSVs:\n",
    "- `users.csv`: page/user attributes such as topics, activity features, and follower statistics  \n",
    "- `edges_follow.csv`: directed “FOLLOW”-style edges constructed from the original MUSAE page–page links  \n",
    "\n",
    "The code below sets up URLs to the curated versions of these files and ensures they are stored under the local `data/curated/` directory.\n",
    "\n",
    "#### Download CSVs (if missing)\n",
    "\n",
    "Run the cell below. If the CSVs already exist locally, the notebook will simply reuse them.\n",
    "\n",
    "#### Load into Pandas and Inspect\n",
    "\n",
    "Once downloaded, the CSVs are loaded into DataFrames so you can examine the first few rows and verify the structure of the Facebook-style social graph before proceeding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>name</th>\n",
       "      <th>company</th>\n",
       "      <th>followers</th>\n",
       "      <th>following</th>\n",
       "      <th>posts_30d</th>\n",
       "      <th>topics</th>\n",
       "      <th>bio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[\"tvshow\"]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>[\"government\"]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"company\"]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   login  name  company  followers  following  posts_30d          topics  bio\n",
       "0      0     0      NaN          1          1          6      [\"tvshow\"]  NaN\n",
       "1      1     1      NaN         34         34          5  [\"government\"]  NaN\n",
       "2      2     2      NaN         12         12          1     [\"company\"]  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>etype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18427</td>\n",
       "      <td>FOLLOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21708</td>\n",
       "      <td>FOLLOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>22208</td>\n",
       "      <td>FOLLOW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   src    dst   etype\n",
       "0    0  18427  FOLLOW\n",
       "1    1  21708  FOLLOW\n",
       "2    1  22208  FOLLOW"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ users=22,470 | edges=341,646\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "USERS_URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/GSNJkoEM3yeeCjJl1l2Jrg/users.csv\"\n",
    "EDGES_URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/m9iBI6GCId0XoGEkjwHk3g/edges-follow.csv\"\n",
    "\n",
    "CUR = Path(\"data/curated\"); CUR.mkdir(parents=True, exist_ok=True)\n",
    "USERS_CSV = CUR / \"users.csv\"\n",
    "EDGES_CSV = CUR / \"edges_follow.csv\"\n",
    "\n",
    "# download only if missing\n",
    "if not USERS_CSV.exists():\n",
    "    pd.read_csv(USERS_URL).to_csv(USERS_CSV, index=False)\n",
    "if not EDGES_CSV.exists():\n",
    "    pd.read_csv(EDGES_URL).to_csv(EDGES_CSV, index=False)\n",
    "\n",
    "df_users = pd.read_csv(USERS_CSV)\n",
    "df_edges = pd.read_csv(EDGES_CSV)\n",
    "display(df_users.head(3))\n",
    "display(df_edges.head(3))\n",
    "print(f\"✅ users={len(df_users):,} | edges={len(df_edges):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check OpenAI Model and API Key\n",
    "\n",
    "Next, we verify that an OpenAI API key is available. The Skills Network environment usually provides this automatically via `OPENAI_API_KEY`.  \n",
    "\n",
    "We also set the preferred LLM model name. If the environment variable is missing, the assertion will raise an error early so you can correct it before continuing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI model: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "\n",
    "# This will raise an error if the key is missing, so you know to fix it early.\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"Set OPENAI_API_KEY in your environment.\"\n",
    "\n",
    "print(\"✅ OpenAI model:\", OPENAI_MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Preprocessing\n",
    "\n",
    "Each user has a `topics` field describing the page’s category. However, these values may appear in several formats including:\n",
    "\n",
    "- Python lists  \n",
    "- JSON-like strings  \n",
    "- Strings with separators  \n",
    "\n",
    "The helper below normalizes all topic representations into a clean list of lowercase strings. This ensures the modules receive consistent topic fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [tvshow]\n",
       "1    [government]\n",
       "2       [company]\n",
       "3    [government]\n",
       "4    [politician]\n",
       "Name: topics, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _topics_field(v):\n",
    "    if isinstance(v, list): return [str(x).lower() for x in v]\n",
    "    if isinstance(v, str) and v.startswith(\"[\"):\n",
    "        try: return [str(x).lower() for x in json.loads(v)]\n",
    "        except Exception: pass\n",
    "    return [t.strip().lower() for t in str(v).split(\"|\") if t.strip()]\n",
    "\n",
    "df_users[\"topics\"] = df_users[\"topics\"].apply(_topics_field)\n",
    "df_users[\"topics\"].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Social-Network Graph\n",
    "\n",
    "Now we convert the `users.csv` and `edges_follow.csv` DataFrames into a directed NetworkX graph.  \n",
    "\n",
    "- Each node corresponds to a Facebook page and stores attributes such as followers, posts, and assigned topics.  \n",
    "- Each edge represents a directed “FOLLOW”-style relationship derived from the MUSAE page–page connections.\n",
    "\n",
    "The resulting graph will serve as the global knowledge graph for Graph-RAG and the GCN ranker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[graph] |V|=22470 |E|=341646\n",
      "Is DAG?  False\n",
      "Weakly connected components: 1\n"
     ]
    }
   ],
   "source": [
    "def build_graph(users_df: pd.DataFrame, edges_df: pd.DataFrame) -> Tuple[nx.DiGraph, pd.DataFrame]:\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes with attributes\n",
    "    for _, r in users_df.iterrows():\n",
    "        G.add_node(\n",
    "            r[\"login\"],\n",
    "            **dict(\n",
    "                name=r.get(\"name\") or r[\"login\"],\n",
    "                company=str(r.get(\"company\", \"\")),\n",
    "                followers=int(r.get(\"followers\", 0)),\n",
    "                following=int(r.get(\"following\", 0)),\n",
    "                posts_30d=int(r.get(\"posts_30d\", 0)),\n",
    "                topics=r.get(\"topics\", []),\n",
    "                bio=str(r.get(\"bio\", \"\")),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Add directed edges\n",
    "    for _, e in edges_df.iterrows():\n",
    "        s, d = e[\"src\"], e[\"dst\"]\n",
    "        if s in G and d in G and s != d:\n",
    "            G.add_edge(s, d, etype=e.get(\"etype\",\"FOLLOW\"))\n",
    "    \n",
    "    return G, users_df\n",
    "\n",
    "G, users_df = build_graph(df_users, df_edges)\n",
    "\n",
    "print(f\"[graph] |V|={G.number_of_nodes()} |E|={G.number_of_edges()}\")\n",
    "print(\"Is DAG? \", nx.is_directed_acyclic_graph(G))\n",
    "print(\"Weakly connected components:\", nx.number_weakly_connected_components(G))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering for GNN\n",
    "\n",
    "We first define helper functions for topic vectors and cosine similarity.\n",
    "\n",
    "To train a GCN that predicts influencer importance, we need numerical feature vectors for each node. Before assembling those feature vectors, we define utility functions for topic vectors and cosine similarity, which allow us to measure topical alignment between a page and a query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_vector(ts, vocab):\n",
    "    v = np.zeros(len(vocab), dtype=np.float32)\n",
    "    idx = {t:i for i,t in enumerate(vocab)}\n",
    "    for t in ts:\n",
    "        if t in idx: v[idx[t]] = 1.0\n",
    "    return v\n",
    "\n",
    "def cosine(a,b):\n",
    "    na,nb = np.linalg.norm(a), np.linalg.norm(b)\n",
    "    return 0.0 if na==0 or nb==0 else float(np.dot(a,b)/(na*nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Node Features\n",
    "\n",
    "The function below constructs the complete feature matrix for the graph.  \n",
    "For each node, we compute:\n",
    "\n",
    "- PageRank  \n",
    "- In-degree and Out-degree  \n",
    "- k-core number (structural cohesion)  \n",
    "- Clustering coefficient  \n",
    "- Recent posting activity  \n",
    "- Topic similarity to the query  \n",
    "\n",
    "The features are optionally normalized to stabilize GCN training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(G: nx.DiGraph, qtopics=None, normalize=True):\n",
    "    vocab = sorted({t for _, d in G.nodes(data=True) for t in d.get(\"topics\", [])})\n",
    "    qv = topic_vector([t.lower() for t in (qtopics or [])], vocab)\n",
    "\n",
    "    Gu = G.to_undirected()\n",
    "\n",
    "    # Deterministic PageRank\n",
    "    pr = {}\n",
    "    if G.number_of_nodes():\n",
    "        nstart = {n: 1.0 / G.number_of_nodes() for n in G}\n",
    "        pr = nx.pagerank(G, nstart=nstart)\n",
    "\n",
    "    deg_in, deg_out = dict(G.in_degree()), dict(G.out_degree())\n",
    "    kcore = nx.core_number(Gu) if G.number_of_nodes() else {n: 0 for n in G}\n",
    "    clust = nx.clustering(Gu) if G.number_of_nodes() else {n: 0.0 for n in G}\n",
    "\n",
    "    X, nodes = [], []\n",
    "    for n, d in G.nodes(data=True):\n",
    "        nodes.append(n)\n",
    "        tv = topic_vector(d.get(\"topics\", []), vocab)\n",
    "        topicality = cosine(tv, qv) if len(qv) else 0.0\n",
    "\n",
    "        X.append([\n",
    "            pr.get(n, 0.0),\n",
    "            deg_in.get(n, 0),\n",
    "            deg_out.get(n, 0),\n",
    "            kcore.get(n, 0),\n",
    "            clust.get(n, 0.0),\n",
    "            d.get(\"posts_30d\", 0),\n",
    "            topicality,\n",
    "        ])\n",
    "\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    if normalize and len(X):\n",
    "        X = (X - X.mean(axis=0, keepdims=True)) / (X.std(axis=0, keepdims=True) + 1e-6)\n",
    "\n",
    "    names = [\"pagerank\", \"deg_in\", \"deg_out\", \"kcore\", \"clust\", \"posts_30d\", \"topic_sim\"]\n",
    "    return nodes, X, names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Simple Influence Target\n",
    "\n",
    "To train a GCN ranker, we need a target value that reflects “influence.” Because no ground-truth labels exist, we construct a heuristic influence score by combining PageRank, degree ratios, activity, and topic relevance.  \n",
    "\n",
    "The GCN will learn to approximate this heuristic but later generalize it across different subgraphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_target(G, nodes, X, names):\n",
    "    idx = {f:i for i,f in enumerate(names)}\n",
    "    s = (0.45*X[:,idx[\"pagerank\"]] +\n",
    "         0.25*(X[:,idx[\"deg_in\"]] / (1+np.maximum(1.0, X[:,idx[\"deg_out\"]]))) +\n",
    "         0.15*X[:,idx[\"posts_30d\"]] +\n",
    "         0.15*X[:,idx[\"topic_sim\"]])\n",
    "    s = (s - s.min())/(1e-8 + (s.max()-s.min()))\n",
    "    return s.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCN-Based Influence Ranker\n",
    "\n",
    "Here we define a simple two-layer Graph Convolutional Network. The model takes the engineered node features and propagates them through graph convolutions, ultimately predicting a scalar influence score for each node. Dropout layers help regularize training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfluenceGCN(nn.Module):\n",
    "    def __init__(self, in_dim, hid=64, p_drop=0.1):\n",
    "        super().__init__()\n",
    "        self.gc1 = GCNConv(in_dim, hid, cached=False, add_self_loops=False)\n",
    "        self.gc2 = GCNConv(hid, hid, cached=False, add_self_loops=False)\n",
    "        self.out = nn.Linear(hid, 1)\n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        h = self.gc1(x, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = self.drop(h)\n",
    "        h = self.gc2(h, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = self.drop(h)\n",
    "        return self.out(h).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Ranking Training\n",
    "\n",
    "We train the GCN ranker using a **pairwise ranking loss**. Instead of predicting absolute values, the GCN learns ordering: if node *i* should rank higher than node *j*, the model is penalized unless `score(i) > score(j)`.  \n",
    "\n",
    "This produces a model optimized for influencer ranking tasks within subgraphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ranker(G, qtopics, epochs=100, lr=2e-3, pairs_per_epoch=1024):\n",
    "    # Build features and heuristic targets\n",
    "    nodes, X, names = make_features(G, qtopics, normalize=True)\n",
    "    y = simple_target(G, nodes, X, names)\n",
    "\n",
    "    # Convert to PyG graph\n",
    "    H = G.to_directed()\n",
    "    d = pyg_from_nx(H)\n",
    "    n2i = {n: i for i, n in enumerate(list(H.nodes()))}\n",
    "\n",
    "    feat = np.zeros((len(n2i), X.shape[1]), dtype=np.float32)\n",
    "    for i, n in enumerate(nodes):\n",
    "        if n in n2i:\n",
    "            feat[n2i[n]] = X[i]\n",
    "\n",
    "    d.x = torch.tensor(feat, dtype=torch.float32, device=device)\n",
    "    d.y = torch.tensor(y, dtype=torch.float32, device=device)\n",
    "    d.edge_index = d.edge_index.to(device)\n",
    "\n",
    "    model = InfluenceGCN(d.x.shape[1]).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    # Pre-draw pairs using a deterministic generator\n",
    "    g = torch.Generator(device=\"cpu\").manual_seed(SEED)\n",
    "    N = d.x.shape[0]\n",
    "    idx_all = torch.randint(0, N, (epochs, pairs_per_epoch), generator=g)\n",
    "    jdx_all = torch.randint(0, N, (epochs, pairs_per_epoch), generator=g)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        s = model(d.x, d.edge_index)\n",
    "        idx = idx_all[ep].to(device)\n",
    "        jdx = jdx_all[ep].to(device)\n",
    "\n",
    "        mask = (d.y[idx] > d.y[jdx])\n",
    "        if mask.any():\n",
    "            loss = -torch.log(torch.sigmoid(s[idx[mask]] - s[jdx[mask]])).mean()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        else:\n",
    "            loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "        if ep % 5 == 0:\n",
    "            print(f\"-train- ep {ep:02d} loss {loss.item():.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gnn] training GCN ranker…\n",
      "-train- ep 00 loss 0.6967\n",
      "-train- ep 05 loss 0.6468\n",
      "-train- ep 10 loss 0.6058\n",
      "-train- ep 15 loss 0.5667\n",
      "-train- ep 20 loss 0.5426\n",
      "-train- ep 25 loss 0.4898\n",
      "-train- ep 30 loss 0.4675\n",
      "-train- ep 35 loss 0.4451\n",
      "-train- ep 40 loss 0.4096\n",
      "-train- ep 45 loss 0.4158\n",
      "-train- ep 50 loss 0.3761\n",
      "-train- ep 55 loss 0.3291\n",
      "-train- ep 60 loss 0.3304\n",
      "-train- ep 65 loss 0.3261\n",
      "-train- ep 70 loss 0.3536\n",
      "-train- ep 75 loss 0.2863\n",
      "-train- ep 80 loss 0.3083\n",
      "-train- ep 85 loss 0.3973\n",
      "-train- ep 90 loss 0.3395\n",
      "-train- ep 95 loss 0.3619\n",
      "✅ Training complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"[gnn] training GCN ranker…\")\n",
    "\n",
    "trained_model = train_ranker(\n",
    "    G,\n",
    "    qtopics=[\"politician\", \"company\", \"tv_show\", \"news\", \"brand\"],\n",
    "    epochs=100,\n",
    "    lr=2e-3,\n",
    ")\n",
    "\n",
    "print(\"✅ Training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Retrieval for a Query\n",
    "\n",
    "To support Graph-RAG, we create utilities that:\n",
    "\n",
    "- Parse a user’s natural-language query and infer coarse topic labels.  \n",
    "- Extract a relevant subgraph by expanding outward from topic-matched seeds.  \n",
    "- Prepare subgraphs for GCN scoring.\n",
    "\n",
    "This enables the agent to retrieve only the portion of the graph relevant to the user query, making the pipeline more efficient and interpretable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_entities(q: str):\n",
    "    q = (q or \"\").lower()\n",
    "    cand = [\"politician\", \"company\", \"tv_show\", \"news\", \"brand\", \"community\", \"sports\", \"music\"]\n",
    "    topics = [t for t in cand if t in q] or [\"politician\", \"company\", \"tv_show\"]\n",
    "    return {\"topics\": topics}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_retrieve(G, ents, k=2, top_n=800):\n",
    "    topics = ents.get(\"topics\", [])\n",
    "\n",
    "    # Seeds: users whose topics intersect the query topics\n",
    "    seeds = [n for n, d in G.nodes(data=True) if set(d.get(\"topics\", [])) & set(topics)] \\\n",
    "            or list(G)[:200]\n",
    "\n",
    "    S = set()\n",
    "    for s in seeds[:100]:\n",
    "        S.add(s)\n",
    "        fringe = {s}\n",
    "        for _ in range(k):\n",
    "            nxt = set()\n",
    "            for u in list(fringe):\n",
    "                nxt |= set(G.successors(u))\n",
    "                nxt |= set(G.predecessors(u))\n",
    "            S |= nxt\n",
    "            fringe = nxt\n",
    "\n",
    "    return G.subgraph(sorted(list(S))[:top_n]).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_subgraph(Gsub, qtopics, model):\n",
    "    nodes, X, names = make_features(Gsub, qtopics, normalize=True)\n",
    "\n",
    "    H = Gsub.to_directed()\n",
    "    d = pyg_from_nx(H)\n",
    "    n2i = {n: i for i, n in enumerate(list(H.nodes()))}\n",
    "\n",
    "    feat = np.zeros((len(n2i), X.shape[1]), dtype=np.float32)\n",
    "    for i, n in enumerate(nodes):\n",
    "        if n in n2i:\n",
    "            feat[n2i[n]] = X[i]\n",
    "\n",
    "    d.x = torch.tensor(feat, dtype=torch.float32, device=device)\n",
    "    d.edge_index = d.edge_index.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        s = trained_model(d.x, d.edge_index).detach().cpu().numpy()\n",
    "\n",
    "    return {n: float(s[n2i[n]]) for n in nodes if n in n2i}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Summarization of Top Influencers\n",
    "\n",
    "Once the subgraph is scored, we use an LLM to summarize the top influencers. This helper function formats the evidence lines and sends them to the OpenAI model, asking it to rank key influencers, justify each ranking, and propose an outreach plan.\n",
    "\n",
    "We now connect to the OpenAI client:\n",
    "\n",
    "- Packs the top-K scored nodes into evidence lines.\n",
    "- Asks the LLM to:\n",
    "  - Rank 3–5 key influencers,\n",
    "  - Provide one-sentence rationales,\n",
    "  - Suggest a short outreach plan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "def llm_summarize(query, topk, Gsub):\n",
    "    bullets = []\n",
    "    for i, (u, sc, _) in enumerate(topk[:8], 1):\n",
    "        d = Gsub.nodes[u]\n",
    "        bullets.append(\n",
    "            f\"{i}. node={u} | score={sc:.2f} | \"\n",
    "            f\"in={Gsub.in_degree(u)} out={Gsub.out_degree(u)} | \"\n",
    "            f\"topics={','.join(d.get('topics', []))} | \"\n",
    "            f\"posts_30d={d.get('posts_30d', 0)}\"\n",
    "        )\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a precise social-graph analyst. Use only the given evidence. \"\n",
    "                \"Return: (1) ranked list (3–5), (2) one-sentence rationale each, \"\n",
    "                \"(3) a short outreach plan grounded in the graph.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"User query: {query}\\nEvidence lines:\\n\" + \"\\n\".join(bullets),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        top_p=1,\n",
    "        max_tokens=500,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agentic Graph-RAG with LangGraph\n",
    "\n",
    "Now we wrap the entire workflow into a LangGraph agent. \n",
    "\n",
    "The agent consists of four nodes:\n",
    "\n",
    "- **plan**: infer query topics  \n",
    "- **retrieve**: extract a relevant subgraph  \n",
    "- **score**: apply the GCN ranker  \n",
    "- **synthesize**: generate a final natural-language summary  \n",
    "\n",
    "LangGraph coordinates the flow between these steps to form a coherent agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LangGraph agent compiled.\n"
     ]
    }
   ],
   "source": [
    "class AgentState(TypedDict, total=False):\n",
    "    query: str\n",
    "    plan: str\n",
    "    entities: Dict[str, Any]\n",
    "    subgraph: nx.DiGraph\n",
    "    scores: Dict[str, float]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def _plan(s: AgentState) -> AgentState:\n",
    "    s[\"plan\"] = \"rank_influencers_and_explain\"\n",
    "    s[\"entities\"] = link_entities(s.get(\"query\", \"\"))\n",
    "    return s\n",
    "\n",
    "\n",
    "def _retrieve(s: AgentState) -> AgentState:\n",
    "    s[\"subgraph\"] = graph_retrieve(G, s[\"entities\"], k=2, top_n=800)\n",
    "    return s\n",
    "\n",
    "\n",
    "def _score(s: AgentState) -> AgentState:\n",
    "    q = s.get(\"entities\", {}).get(\"topics\", [])\n",
    "    s[\"scores\"] = score_subgraph(s[\"subgraph\"], q, model=trained_model)\n",
    "    return s\n",
    "\n",
    "\n",
    "def _synthesize(s: AgentState) -> AgentState:\n",
    "    q = s.get(\"entities\", {}).get(\"topics\", [])\n",
    "    nodes, X, names = make_features(s[\"subgraph\"], q)\n",
    "\n",
    "    # PageRank on the subgraph for extra explanation features\n",
    "    pr = (\n",
    "        nx.pagerank(\n",
    "            s[\"subgraph\"],\n",
    "            nstart={n: 1 / max(1, s[\"subgraph\"].number_of_nodes()) for n in s[\"subgraph\"]},\n",
    "        )\n",
    "        if s[\"subgraph\"].number_of_nodes()\n",
    "        else {}\n",
    "    )\n",
    "\n",
    "    triples = []\n",
    "    for u in nodes:\n",
    "        sc = s[\"scores\"].get(u, 0.0)\n",
    "        d = s[\"subgraph\"].nodes[u]\n",
    "        why = (\n",
    "            f\"PR~{pr.get(u, 0):.2f}, \"\n",
    "            f\"deg_in={s['subgraph'].in_degree(u)}, \"\n",
    "            f\"posts={d.get('posts_30d', 0)}, \"\n",
    "            f\"topics={','.join(d.get('topics', []))}\"\n",
    "        )\n",
    "        triples.append((u, sc, why))\n",
    "\n",
    "    triples.sort(key=lambda x: (-x[1], str(x[0])))\n",
    "    topk = triples[:10]\n",
    "\n",
    "    s[\"answer\"] = llm_summarize(s.get(\"query\", \"\"), topk, s[\"subgraph\"])\n",
    "    s[\"scores\"] = {u: sc for u, sc, _ in topk}\n",
    "    return s\n",
    "\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"plan\", _plan)\n",
    "graph.add_node(\"retrieve\", _retrieve)\n",
    "graph.add_node(\"score\", _score)\n",
    "graph.add_node(\"synthesize\", _synthesize)\n",
    "\n",
    "graph.add_edge(START, \"plan\")\n",
    "graph.add_edge(\"plan\", \"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"score\")\n",
    "graph.add_edge(\"score\", \"synthesize\")\n",
    "graph.add_edge(\"synthesize\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "print(\"✅ LangGraph agent compiled.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Agent on a Sample Query\n",
    "\n",
    "Let’s run the full Agentic Graph-RAG pipeline on a sample query. This will show how the agent retrieves a subgraph, scores influencers, and produces a well-structured natural-language response.\n",
    "\n",
    "Let’s try a query that mixes *politician* and *company* contexts and inspect the agent’s answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Agent Answer (model: gpt-4o-mini) ===\n",
      "\n",
      "### Ranked List of Influencers\n",
      "\n",
      "1. **Node 701** (Score: 39.35, Topics: Company)\n",
      "   - Rationale: With the highest score and a balanced number of posts, this influencer is well-positioned to engage with company-related content effectively.\n",
      "\n",
      "2. **Node 1387** (Score: 24.29, Topics: Government)\n",
      "   - Rationale: This influencer has a strong score and a solid engagement in government topics, making them a key player for political outreach.\n",
      "\n",
      "3. **Node 290** (Score: 20.95, Topics: Politician)\n",
      "   - Rationale: This influencer focuses on political content and has a good number of posts, indicating active engagement in the political sphere.\n",
      "\n",
      "4. **Node 1193** (Score: 18.68, Topics: Politician)\n",
      "   - Rationale: Although slightly lower in score, this influencer still contributes to political discussions and can be valuable for outreach.\n",
      "\n",
      "5. **Node 961** (Score: 18.14, Topics: Government)\n",
      "   - Rationale: This influencer has a decent score and is involved in government topics, making them relevant for political and governmental outreach.\n",
      "\n",
      "### Outreach Plan\n",
      "\n",
      "1. **Identify Key Messages**: Develop tailored messages that resonate with each influencer's audience, focusing on the intersection of their topics and the politician/company's goals.\n",
      "\n",
      "2. **Engagement Strategy**: Initiate contact through social media platforms, commenting on their posts, and sharing relevant content to build rapport before direct outreach.\n",
      "\n",
      "3. **Collaborative Opportunities**: Propose collaboration opportunities such as interviews, guest posts, or joint events that align with their interests and expertise.\n",
      "\n",
      "4. **Content Sharing**: Encourage influencers to share content that highlights the politician's or company's initiatives, ensuring it aligns with their established themes to maintain authenticity.\n",
      "\n",
      "5. **Feedback Loop**: Establish a feedback mechanism to assess the effectiveness of the outreach and adjust strategies based on influencer engagement and audience response.\n"
     ]
    }
   ],
   "source": [
    "query = \"Find influencers for politician and company pages\"\n",
    "\n",
    "res = app.invoke({\"query\": query})\n",
    "\n",
    "print(f\"\\n=== Agent Answer (model: {OPENAI_MODEL}) ===\\n\")\n",
    "print(res[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Top Influencer Neighborhoods\n",
    "\n",
    "Finally, we visualize the local neighborhoods around the top-ranked influencers. This helps us understand why these nodes matter by showing their 1-hop connections and relative structural influence within the subgraph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top3(G, scores, hops=1, title=\"Top-3 influencer neighborhoods\"):\n",
    "    top = [u for u, _ in sorted(scores.items(), key=lambda x: (-x[1], str(x[0])))[:3]]\n",
    "\n",
    "    H = nx.DiGraph()\n",
    "    for c in top:\n",
    "        if c not in G:\n",
    "            continue\n",
    "        H.add_node(c, **G.nodes[c])\n",
    "        fringe = {c}\n",
    "        for _ in range(hops):\n",
    "            nxt = set()\n",
    "            for u in list(fringe):\n",
    "                for v in G.successors(u):\n",
    "                    H.add_node(v, **G.nodes[v])\n",
    "                    H.add_edge(u, v)\n",
    "                    nxt.add(v)\n",
    "                for v in G.predecessors(u):\n",
    "                    H.add_node(v, **G.nodes[v])\n",
    "                    H.add_edge(v, u)\n",
    "                    nxt.add(v)\n",
    "            fringe = nxt\n",
    "\n",
    "    if H.number_of_nodes() == 0:\n",
    "        print(\"[viz] empty\")\n",
    "    else:\n",
    "        pos = nx.spring_layout(H, seed=SEED)\n",
    "        ns = [6 + 2 * H.in_degree(n) for n in H.nodes()]\n",
    "        nx.draw_networkx_nodes(H, pos, node_size=ns, alpha=0.85)\n",
    "        nx.draw_networkx_edges(H, pos, alpha=0.25, arrows=True)\n",
    "        nx.draw_networkx_labels(H, pos, font_size=7)\n",
    "        plt.title(title)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot_top3(G, res.get(\"scores\", {}), hops=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This lab showed how graph structure, neural ranking, and agentic LLM reasoning can be combined to analyze influence in a social network. By building a Page–Page graph, engineering features, and training a GCN ranker, we created a model that captures both local and global patterns of connectivity. Integrating the ranker into a LangGraph agent enabled a full Graph-RAG workflow: planning from a natural-language query, retrieving a meaningful subgraph, and generating actionable summaries.\n",
    "\n",
    "The final system demonstrates how graph-aware retrieval and learned influence modeling provide deeper, more interpretable insights than text-only RAG approaches. Visualizations such as the top influencer neighborhoods highlight how structural patterns drive the agent’s decisions. This foundation can be extended with richer GNNs, temporal analysis, or more advanced agentic behaviors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- Kipf, T. N., & Welling, M. (2017). Semi-Supervised Classification with Graph Convolutional Networks. International Conference on Learning Representations (ICLR).\n",
    "- The social-network dataset used in this lab is based on the **MUSAE Facebook Page–Page network**: https://snap.stanford.edu/data/facebook-large-page-page-network.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "4a1ecdad4374141a98e79a1c61c331ebdaaa1cb284b25ef8593938c0a5539764"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
