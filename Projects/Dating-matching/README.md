# ðŸ¤– Couple Matching Probability â€” AI-Powered Speed Dating Match Prediction Agent

![Python](https://img.shields.io/badge/Python-3.8%2B-blue?style=flat-square&logo=python)
![LangGraph](https://img.shields.io/badge/LangGraph-1.0.8-purple?style=flat-square)
![XGBoost](https://img.shields.io/badge/XGBoost-3.2.0-orange?style=flat-square)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-1.8.0-yellow?style=flat-square)
![LangChain](https://img.shields.io/badge/LangChain-1.2.10-green?style=flat-square)
![OpenAI](https://img.shields.io/badge/GPT--4o--mini-OpenAI-black?style=flat-square&logo=openai)
![License](https://img.shields.io/badge/License-MIT-lightgrey?style=flat-square)

---

## ðŸ“– Overview

What makes two people click in just four minutes? Can machine learning predict romantic chemistry before a date even ends?

This project answers exactly that â€” by building an **autonomous AI agent** that takes a single natural language instruction and independently orchestrates an entire machine learning pipeline: from raw messy data all the way to a trained probability model with an **ROC AUC score of 0.8341**.

Unlike traditional ML pipelines where you manually chain each step, this project uses **LangGraph** and the **ReAct (Reason + Act) pattern** to create an intelligent agent that *reasons* about what needs to happen next and *acts* by calling the right tool at the right time â€” completely on its own.

---

## ðŸŽ¯ Project Highlights

- âœ… Built an end-to-end **agentic ML workflow** from a single prompt
- âœ… Achieved **ROC AUC = 0.8341** on real speed dating data
- âœ… Automated data cleaning, feature selection, and model training with **zero manual intervention**
- âœ… Identified the top 10 most predictive features for romantic matching
- âœ… Handled real-world data challenges: byte-string encodings, missing values, and data leakage

---

## ðŸ§  What Is an Agentic Workflow?

Traditional ML pipelines require you to:
- Manually write each step in the correct order
- Pass data between functions yourself
- Track intermediate results
- Handle errors at every stage

An **agentic workflow** delegates all of this to an AI. You give it a goal â€” the agent figures out the path.

This project demonstrates that pattern end-to-end using **LangGraph's StateGraph** and the **ReAct loop**:

```
[Reason] â†’ What should I do next?
[Act]    â†’ Call the appropriate tool
[Observe]â†’ Process the tool's output
[Repeat] â†’ Until the task is complete
```

---

## ðŸ“Š Dataset

**Source:** [Speed Dating Dataset â€” Kaggle (Ulrik Thyge Pedersen)](https://www.kaggle.com/datasets/ulrikthygepedersen/speed-dating/data)

| Property | Detail |
|---|---|
| Rows | 8,378 |
| Target Variable | `match` (1 = both said yes, 0 = otherwise) |
| Key Features | Attractiveness, sincerity, intelligence, fun, ambition, shared interests ratings |
| Data Challenges | Byte-string encodings, missing values, leakage columns |

### âš ï¸ Data Leakage Addressed
The columns `decision` and `decision_o` (individual yes/no votes) were deliberately removed. Knowing both votes makes the match deterministic â€” that's not prediction, that's peeking. The model predicts purely from ratings and demographics.

---

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LangGraph StateGraph            â”‚
â”‚                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ Scientistâ”‚â”€â”€â”€â”€â”€â–¶â”‚   Tools Node     â”‚    â”‚
â”‚   â”‚  (LLM)   â”‚â—€â”€â”€â”€â”€â”€â”‚                  â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ â€¢ clean_data     â”‚    â”‚
â”‚        â”‚            â”‚ â€¢ select_featuresâ”‚    â”‚
â”‚        â–¼            â”‚ â€¢ train_model    â”‚    â”‚
â”‚      [END]          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Router Logic:**
- If the LLM response contains tool calls â†’ route to `tools` node
- If no tool calls remain â†’ route to `END`
- After every tool execution â†’ return to `scientist` node

---

## ðŸ› ï¸ Tools Defined

### 1. `clean_speed_dating_data(file_name)`
Handles all preprocessing in one pass:
- Drops leakage columns (`decision`, `decision_o`, `has_null`)
- Strips byte-string encodings (e.g., `b'female'` â†’ `female`)
- Label-encodes all categorical variables
- Imputes missing values using median strategy
- Saves cleaned output to `cleaned_data.csv`

### 2. `select_top_features(n_features)`
Runs intelligent feature selection:
- Uses **Recursive Feature Elimination (RFE)** backed by a Random Forest
- Ranks features by predictive importance
- Returns the top N features for model training

**Top 10 Features Selected:**
| # | Feature | What It Means |
|---|---|---|
| 1 | `attractive_o` | How attractive you rated your partner |
| 2 | `like` | Overall how much you liked them |
| 3 | `guess_prob_liked` | How likely you think they liked you |
| 4 | `interests_correlate` | Correlation of your interests |
| 5 | `shared_interests_o` | Shared interests score |
| 6 | `funny_o` | How funny you rated them |
| 7 | `attractive_partner` | How important attractiveness was to you |
| 8 | `attractive_important` | Attractiveness preference weight |
| 9 | `pref_o_attractive` | Partner's attractiveness preference |
| 10 | `field` | Field of study |

### 3. `train_probability_model(features)`
Trains and evaluates the final model:
- Splits data 80/20 with stratification
- Trains an **XGBoost classifier**
- Predicts match *probabilities* (not just binary labels)
- Evaluates using **ROC AUC** â€” the gold standard for probability ranking

---

## ðŸ“ˆ Results

| Metric | Score |
|---|---|
| **ROC AUC** | **0.8341** |
| Training Data | 6,702 rows |
| Test Data | 1,676 rows |
| Features Used | 10 |

> An ROC AUC of 0.8341 means the model correctly ranks a true match above a non-match **83.41% of the time** â€” using only ratings and demographics, with no knowledge of individual decisions.

---

## âš™ï¸ Tech Stack

| Tool | Version | Role |
|---|---|---|
| **LangGraph** | 1.0.8 | Agentic workflow orchestration |
| **LangChain** | 1.2.10 | LLM integration & tool binding |
| **GPT-4o-mini** | via OpenAI | Reasoning engine (ReAct brain) |
| **XGBoost** | 3.2.0 | Probability model training |
| **Scikit-learn** | 1.8.0 | RFE feature selection & preprocessing |
| **Pandas** | 3.0.0 | Data manipulation |
| **NumPy** | 2.4.2 | Numerical operations |

---

## ðŸš€ Getting Started

### Prerequisites
- Python 3.8+
- OpenAI API key

### Installation

```bash
# Clone the repository
git clone https://github.com/your-username/couple-matching-probability.git
cd couple-matching-probability

# Install dependencies
pip install langchain==1.2.10 langchain-openai==1.1.9 langgraph==1.0.8 \
            openai==2.20.0 numpy==2.4.2 pandas==3.0.0 \
            scikit-learn==1.8.0 xgboost==3.2.0
```

### Set Your API Key

```bash
export OPENAI_API_KEY="your-openai-api-key"
```

### Download the Dataset

```bash
wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/sqiJ_CW9x_k2T6C2KgPf6Q/speeddating.csv
```

### Run the Agent

```python
from langchain_core.messages import HumanMessage

query = "Clean 'speeddating.csv', select top 10 features, and predict match probability."

for output in app.stream({"messages": [HumanMessage(content=query)]}, stream_mode="updates"):
    for node_name, state_update in output.items():
        if node_name == "scientist":
            message = state_update["messages"][-1]
            if message.tool_calls:
                print(f"ðŸ¤” THOUGHT: Calling {[t['name'] for t in message.tool_calls]}")
            else:
                print(f"âœ… FINAL ANALYSIS:\n{message.content}")
        elif node_name == "tools":
            for tool_msg in state_update["messages"]:
                print(f"ðŸ‘ï¸ OBSERVATION: {str(tool_msg.content)[:300]}")
```

### Expected Output

```
ðŸ¤” THOUGHT: Calling ['clean_speed_dating_data']
ðŸ‘ï¸ OBSERVATION: Data cleaned. Rows: 8378. Saved to 'cleaned_data.csv'...

ðŸ¤” THOUGHT: Calling ['select_top_features']
ðŸ‘ï¸ OBSERVATION: {"selected_features": ["attractive_o", "like", "guess_prob_liked", ...]}

ðŸ¤” THOUGHT: Calling ['train_probability_model']
ðŸ‘ï¸ OBSERVATION: Model trained. ROC AUC Score: 0.8341. Predictions are reliable...

âœ… FINAL ANALYSIS:
The model achieved a ROC AUC of 0.8341 using the top 10 features...

ðŸ Workflow Complete.
```

---

## ðŸ”¬ Extending the Project

Some ideas to take this further:

- **Hyperparameter tuning** â€” Let the agent experiment with XGBoost parameters autonomously
- **Multi-model comparison** â€” Add tools for Logistic Regression, LightGBM, and let the agent pick the best
- **Feature count experiments** â€” Run the pipeline with 5, 10, and 15 features and compare AUC scores
- **SHAP explainability** â€” Add a tool that generates feature importance visualizations
- **Real-time prediction** â€” Build a simple UI where users input ratings and get a match probability score

---

## ðŸ“ Project Structure

```
couple-matching-probability/
â”‚
â”œâ”€â”€ Couple_Matching_Probability.ipynb   # Main notebook
â”œâ”€â”€ speeddating.csv                     # Raw dataset
â”œâ”€â”€ cleaned_data.csv                    # Cleaned dataset (generated)
â””â”€â”€ README.md                           # You are here
```

---

## ðŸ™‹ Author

**Solomon Eniola Adegoke**

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=flat-square&logo=linkedin)](https://www.linkedin.com/in/solomon-eniola-adegoke/)

---

## ðŸ“„ License

This project is licensed under the MIT License. Feel free to use, modify, and build on it.

---

> *"Real connection â€” between people or between a model and the truth â€” comes down to the right signals, handled the right way."*
